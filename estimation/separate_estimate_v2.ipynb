{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add warehouse data\n",
    "entry2_data = pd.read_csv(\"entry_loc2.csv\")\n",
    "entry2_data = entry2_data.dropna()\n",
    "entry2_data['HD entry'] = 1*(entry2_data['HD'] > 0)\n",
    "entry2_data['LOW entry'] = 1*(entry2_data['LOW'] > 0)\n",
    "entry2_data['log income'] = np.log(1 + entry2_data['income_per_capita'])\n",
    "entry2_data['log population'] = np.log(1 + entry2_data['population'])\n",
    "entry2_data['log hd warehouse'] = np.log(1 + entry2_data['hd warehouse distance'])\n",
    "entry2_data['log low warehouse'] = np.log(1 + entry2_data['low warehouse distance'])\n",
    "entry2_data = entry2_data[(entry2_data['population']>=2000) & (entry2_data['income_per_capita']>=15000)]\n",
    "entry2_data = entry2_data[(entry2_data['lon'] <= -30) & (entry2_data['lat'] >= 25) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry2_data = entry2_data[entry2_data['population']>10000]\n",
    "entry2_data['interaction1'] = entry2_data['LOW entry'] * entry2_data['log income']\n",
    "entry2_data['interaction2'] = entry2_data['HD entry'] * entry2_data['log income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               HD entry   R-squared:                       0.999\n",
      "Model:                            OLS   Adj. R-squared:                  0.999\n",
      "Method:                 Least Squares   F-statistic:                 6.086e+05\n",
      "Date:                Thu, 01 Jul 2021   Prob (F-statistic):               0.00\n",
      "Time:                        14:11:09   Log-Likelihood:                 8256.9\n",
      "No. Observations:                2952   AIC:                        -1.650e+04\n",
      "Df Residuals:                    2946   BIC:                        -1.647e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const                0.2479      0.009     28.033      0.000       0.231       0.265\n",
      "log income          -0.0241      0.001    -30.541      0.000      -0.026      -0.023\n",
      "log population    1.364e-05      0.000      0.040      0.968      -0.001       0.001\n",
      "log hd warehouse     0.0002      0.000      1.005      0.315      -0.000       0.001\n",
      "LOW entry           -0.0012      0.001     -1.845      0.065      -0.002    7.57e-05\n",
      "interaction2         0.0969   6.38e-05   1518.799      0.000       0.097       0.097\n",
      "==============================================================================\n",
      "Omnibus:                      260.105   Durbin-Watson:                   1.977\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              927.806\n",
      "Skew:                          -0.399   Prob(JB):                    3.39e-202\n",
      "Kurtosis:                       5.628   Cond. No.                         517.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Model fit for HD stores\n",
    "x = entry2_data[['log income','log population','log hd warehouse','LOW entry', 'interaction2']].copy()\n",
    "y = entry2_data['HD entry']\n",
    "model1 = sm.OLS(y,sm.add_constant(x)).fit()\n",
    "print(model1.summary())\n",
    "#print(model1.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "PerfectSeparationError",
     "evalue": "Perfect separation detected, results not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPerfectSeparationError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-90ed3044216f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLogit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#print(model1.summary().as_latex())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m   1972\u001b[0m     def fit(self, start_params=None, method='newton', maxiter=35,\n\u001b[0;32m   1973\u001b[0m             full_output=1, disp=1, callback=None, **kwargs):\n\u001b[1;32m-> 1974\u001b[1;33m         bnryfit = super().fit(start_params=start_params,\n\u001b[0m\u001b[0;32m   1975\u001b[0m                               \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1976\u001b[0m                               \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[1;32mpass\u001b[0m  \u001b[1;31m# TODO: make a function factory to have multiple call-backs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m         mlefit = super().fit(start_params=start_params,\n\u001b[0m\u001b[0;32m    228\u001b[0m                              \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                              \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[0mwarn_convergence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'warn_convergence'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m         xopt, retvals, optim_settings = optimizer._fit(f, score, start_params,\n\u001b[0m\u001b[0;32m    520\u001b[0m                                                        \u001b[0mfargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m                                                        \u001b[0mhessian\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_funcs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         xopt, retvals = func(objective, gradient, start_params, fargs, kwargs,\n\u001b[0m\u001b[0;32m    225\u001b[0m                             \u001b[0mdisp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m                             \u001b[0mretall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py\u001b[0m in \u001b[0;36m_fit_newton\u001b[1;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess, ridge_factor)\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m         \u001b[0miterations\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[0mfval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# this is the negative likelihood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\u001b[0m in \u001b[0;36m_check_perfect_pred\u001b[1;34m(self, params, *args)\u001b[0m\n\u001b[0;32m    209\u001b[0m                 np.allclose(fittedvalues - endog, 0)):\n\u001b[0;32m    210\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Perfect separation detected, results not available\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mPerfectSeparationError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPerfectSeparationError\u001b[0m: Perfect separation detected, results not available"
     ]
    }
   ],
   "source": [
    "model1 = sm.Logit(y,sm.add_constant(x)).fit()\n",
    "print(model1.summary())\n",
    "#print(model1.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HD</td>        <th>  R-squared:         </th> <td>   0.628</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.628</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   996.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 01 Jul 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:11:11</td>     <th>  Log-Likelihood:    </th> <td> -2412.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2952</td>      <th>  AIC:               </th> <td>   4837.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2946</td>      <th>  BIC:               </th> <td>   4873.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>            <td>   -0.8735</td> <td>    0.328</td> <td>   -2.665</td> <td> 0.008</td> <td>   -1.516</td> <td>   -0.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log income</th>       <td>    0.0027</td> <td>    0.029</td> <td>    0.093</td> <td> 0.926</td> <td>   -0.055</td> <td>    0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log population</th>   <td>    0.0905</td> <td>    0.013</td> <td>    6.864</td> <td> 0.000</td> <td>    0.065</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log hd warehouse</th> <td>   -0.0341</td> <td>    0.009</td> <td>   -3.770</td> <td> 0.000</td> <td>   -0.052</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LOW</th>              <td>    0.5108</td> <td>    0.017</td> <td>   30.162</td> <td> 0.000</td> <td>    0.478</td> <td>    0.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>interaction2</th>     <td>    0.0931</td> <td>    0.002</td> <td>   39.774</td> <td> 0.000</td> <td>    0.088</td> <td>    0.098</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>4915.560</td> <th>  Durbin-Watson:     </th>  <td>   1.763</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>6175416.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>10.812</td>  <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>226.023</td> <th>  Cond. No.          </th>  <td>    516.</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HD   R-squared:                       0.628\n",
       "Model:                            OLS   Adj. R-squared:                  0.628\n",
       "Method:                 Least Squares   F-statistic:                     996.0\n",
       "Date:                Thu, 01 Jul 2021   Prob (F-statistic):               0.00\n",
       "Time:                        14:11:11   Log-Likelihood:                -2412.3\n",
       "No. Observations:                2952   AIC:                             4837.\n",
       "Df Residuals:                    2946   BIC:                             4873.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "const               -0.8735      0.328     -2.665      0.008      -1.516      -0.231\n",
       "log income           0.0027      0.029      0.093      0.926      -0.055       0.060\n",
       "log population       0.0905      0.013      6.864      0.000       0.065       0.116\n",
       "log hd warehouse    -0.0341      0.009     -3.770      0.000      -0.052      -0.016\n",
       "LOW                  0.5108      0.017     30.162      0.000       0.478       0.544\n",
       "interaction2         0.0931      0.002     39.774      0.000       0.088       0.098\n",
       "==============================================================================\n",
       "Omnibus:                     4915.560   Durbin-Watson:                   1.763\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          6175416.079\n",
       "Skew:                          10.812   Prob(JB):                         0.00\n",
       "Kurtosis:                     226.023   Cond. No.                         516.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model fit for HD stores\n",
    "x = entry2_data[['log income','log population','log hd warehouse','LOW', 'interaction2']].copy()\n",
    "y = entry2_data['HD']\n",
    "model1 = sm.OLS(y,sm.add_constant(x)).fit()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              LOW entry   R-squared:                       0.999\n",
      "Model:                            OLS   Adj. R-squared:                  0.999\n",
      "Method:                 Least Squares   F-statistic:                 7.014e+05\n",
      "Date:                Thu, 01 Jul 2021   Prob (F-statistic):               0.00\n",
      "Time:                        14:11:12   Log-Likelihood:                 8530.8\n",
      "No. Observations:                2952   AIC:                        -1.705e+04\n",
      "Df Residuals:                    2946   BIC:                        -1.701e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                 0.2061      0.008     26.145      0.000       0.191       0.222\n",
      "log income           -0.0192      0.001    -26.997      0.000      -0.021      -0.018\n",
      "log population       -0.0005      0.000     -1.500      0.134      -0.001       0.000\n",
      "log low warehouse    -0.0004      0.000     -1.510      0.131      -0.001       0.000\n",
      "HD entry             -0.0034      0.001     -5.730      0.000      -0.005      -0.002\n",
      "interaction1          0.0974   5.81e-05   1678.129      0.000       0.097       0.098\n",
      "==============================================================================\n",
      "Omnibus:                      581.471   Durbin-Watson:                   1.979\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3372.903\n",
      "Skew:                          -0.806   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.982   Cond. No.                         511.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Model fit for LO stores\n",
    "x = entry2_data[['log income','log population','log low warehouse','HD entry','interaction1']].copy()\n",
    "y = entry2_data['LOW entry']\n",
    "model1 = sm.regression.linear_model.OLS(y,sm.add_constant(x)).fit()\n",
    "print(model1.summary())\n",
    "#print(model1.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "PerfectSeparationError",
     "evalue": "Perfect separation detected, results not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPerfectSeparationError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-e3ace5cadacb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLogit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# doesn't work when interaction term in model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#print(model1.summary().as_latex())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m   1972\u001b[0m     def fit(self, start_params=None, method='newton', maxiter=35,\n\u001b[0;32m   1973\u001b[0m             full_output=1, disp=1, callback=None, **kwargs):\n\u001b[1;32m-> 1974\u001b[1;33m         bnryfit = super().fit(start_params=start_params,\n\u001b[0m\u001b[0;32m   1975\u001b[0m                               \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1976\u001b[0m                               \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[1;32mpass\u001b[0m  \u001b[1;31m# TODO: make a function factory to have multiple call-backs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m         mlefit = super().fit(start_params=start_params,\n\u001b[0m\u001b[0;32m    228\u001b[0m                              \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                              \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[0mwarn_convergence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'warn_convergence'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m         xopt, retvals, optim_settings = optimizer._fit(f, score, start_params,\n\u001b[0m\u001b[0;32m    520\u001b[0m                                                        \u001b[0mfargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m                                                        \u001b[0mhessian\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_funcs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         xopt, retvals = func(objective, gradient, start_params, fargs, kwargs,\n\u001b[0m\u001b[0;32m    225\u001b[0m                             \u001b[0mdisp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m                             \u001b[0mretall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py\u001b[0m in \u001b[0;36m_fit_newton\u001b[1;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess, ridge_factor)\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m         \u001b[0miterations\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[0mfval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# this is the negative likelihood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\u001b[0m in \u001b[0;36m_check_perfect_pred\u001b[1;34m(self, params, *args)\u001b[0m\n\u001b[0;32m    209\u001b[0m                 np.allclose(fittedvalues - endog, 0)):\n\u001b[0;32m    210\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Perfect separation detected, results not available\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mPerfectSeparationError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPerfectSeparationError\u001b[0m: Perfect separation detected, results not available"
     ]
    }
   ],
   "source": [
    "model1 = sm.Logit(y,sm.add_constant(x)).fit()    # doesn't work when interaction term in model\n",
    "model1.summary()\n",
    "#print(model1.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>LOW</td>       <th>  R-squared:         </th> <td>   0.777</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.776</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2051.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 01 Jul 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:11:17</td>     <th>  Log-Likelihood:    </th> <td> -844.63</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2952</td>      <th>  AIC:               </th> <td>   1701.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2946</td>      <th>  BIC:               </th> <td>   1737.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>             <td>    0.0271</td> <td>    0.189</td> <td>    0.143</td> <td> 0.886</td> <td>   -0.344</td> <td>    0.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log income</th>        <td>   -0.0263</td> <td>    0.017</td> <td>   -1.548</td> <td> 0.122</td> <td>   -0.060</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log population</th>    <td>    0.0224</td> <td>    0.008</td> <td>    2.907</td> <td> 0.004</td> <td>    0.007</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log low warehouse</th> <td>   -0.0084</td> <td>    0.006</td> <td>   -1.382</td> <td> 0.167</td> <td>   -0.020</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HD</th>                <td>    0.2749</td> <td>    0.008</td> <td>   35.768</td> <td> 0.000</td> <td>    0.260</td> <td>    0.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>interaction1</th>      <td>    0.0959</td> <td>    0.001</td> <td>   69.984</td> <td> 0.000</td> <td>    0.093</td> <td>    0.099</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>3744.956</td> <th>  Durbin-Watson:     </th>  <td>   1.766</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1149416.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 6.615</td>  <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>98.759</td>  <th>  Cond. No.          </th>  <td>    512.</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    LOW   R-squared:                       0.777\n",
       "Model:                            OLS   Adj. R-squared:                  0.776\n",
       "Method:                 Least Squares   F-statistic:                     2051.\n",
       "Date:                Thu, 01 Jul 2021   Prob (F-statistic):               0.00\n",
       "Time:                        14:11:17   Log-Likelihood:                -844.63\n",
       "No. Observations:                2952   AIC:                             1701.\n",
       "Df Residuals:                    2946   BIC:                             1737.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "const                 0.0271      0.189      0.143      0.886      -0.344       0.398\n",
       "log income           -0.0263      0.017     -1.548      0.122      -0.060       0.007\n",
       "log population        0.0224      0.008      2.907      0.004       0.007       0.038\n",
       "log low warehouse    -0.0084      0.006     -1.382      0.167      -0.020       0.004\n",
       "HD                    0.2749      0.008     35.768      0.000       0.260       0.290\n",
       "interaction1          0.0959      0.001     69.984      0.000       0.093       0.099\n",
       "==============================================================================\n",
       "Omnibus:                     3744.956   Durbin-Watson:                   1.766\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1149416.257\n",
       "Skew:                           6.615   Prob(JB):                         0.00\n",
       "Kurtosis:                      98.759   Cond. No.                         512.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model fit for LOW stores\n",
    "x = entry2_data[['log income','log population','log low warehouse','HD','interaction1']].copy()\n",
    "y = entry2_data['LOW']\n",
    "model1 = sm.regression.linear_model.OLS(y,sm.add_constant(x)).fit()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.495107\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>LOW entry</td>    <th>  No. Observations:  </th>   <td>  2952</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  2944</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     7</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 01 Jul 2021</td> <th>  Pseudo R-squ.:     </th>   <td>0.2047</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:55:53</td>     <th>  Log-Likelihood:    </th>  <td> -1461.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -1837.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>3.445e-158</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>             <td>    0.9909</td> <td>    1.580</td> <td>    0.627</td> <td> 0.530</td> <td>   -2.105</td> <td>    4.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log income</th>        <td>   -0.9902</td> <td>    0.146</td> <td>   -6.791</td> <td> 0.000</td> <td>   -1.276</td> <td>   -0.704</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log population</th>    <td>    0.6649</td> <td>    0.058</td> <td>   11.468</td> <td> 0.000</td> <td>    0.551</td> <td>    0.778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log low warehouse</th> <td>    0.0750</td> <td>    0.048</td> <td>    1.557</td> <td> 0.119</td> <td>   -0.019</td> <td>    0.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HD entry</th>          <td>    1.3816</td> <td>    0.098</td> <td>   14.114</td> <td> 0.000</td> <td>    1.190</td> <td>    1.573</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Northeast</th>         <td>   -0.0333</td> <td>    0.181</td> <td>   -0.184</td> <td> 0.854</td> <td>   -0.388</td> <td>    0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Midwest</th>           <td>    0.2171</td> <td>    0.137</td> <td>    1.588</td> <td> 0.112</td> <td>   -0.051</td> <td>    0.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>South</th>             <td>    1.2561</td> <td>    0.127</td> <td>    9.875</td> <td> 0.000</td> <td>    1.007</td> <td>    1.505</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              LOW entry   No. Observations:                 2952\n",
       "Model:                          Logit   Df Residuals:                     2944\n",
       "Method:                           MLE   Df Model:                            7\n",
       "Date:                Thu, 01 Jul 2021   Pseudo R-squ.:                  0.2047\n",
       "Time:                        14:55:53   Log-Likelihood:                -1461.6\n",
       "converged:                       True   LL-Null:                       -1837.8\n",
       "Covariance Type:            nonrobust   LLR p-value:                3.445e-158\n",
       "=====================================================================================\n",
       "                        coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "const                 0.9909      1.580      0.627      0.530      -2.105       4.087\n",
       "log income           -0.9902      0.146     -6.791      0.000      -1.276      -0.704\n",
       "log population        0.6649      0.058     11.468      0.000       0.551       0.778\n",
       "log low warehouse     0.0750      0.048      1.557      0.119      -0.019       0.169\n",
       "HD entry              1.3816      0.098     14.114      0.000       1.190       1.573\n",
       "Northeast            -0.0333      0.181     -0.184      0.854      -0.388       0.321\n",
       "Midwest               0.2171      0.137      1.588      0.112      -0.051       0.485\n",
       "South                 1.2561      0.127      9.875      0.000       1.007       1.505\n",
       "=====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model fit for LO stores\n",
    "x = entry2_data[['log income','log population','log low warehouse','HD entry','Northeast', 'Midwest', 'South']].copy()\n",
    "y = entry2_data['LOW entry']\n",
    "model1 = sm.Logit(y,sm.add_constant(x)).fit()    # doesn't work when interaction term in model\n",
    "model1.summary()\n",
    "#print(model1.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.514880\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>HD entry</td>     <th>  No. Observations:  </th>   <td>  2952</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  2944</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     7</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 01 Jul 2021</td> <th>  Pseudo R-squ.:     </th>   <td>0.1988</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:56:02</td>     <th>  Log-Likelihood:    </th>  <td> -1519.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -1897.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.246e-158</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>             <td>  -10.3008</td> <td>    1.489</td> <td>   -6.918</td> <td> 0.000</td> <td>  -13.219</td> <td>   -7.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log income</th>        <td>   -0.0317</td> <td>    0.131</td> <td>   -0.242</td> <td> 0.808</td> <td>   -0.288</td> <td>    0.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log population</th>    <td>    0.9161</td> <td>    0.058</td> <td>   15.694</td> <td> 0.000</td> <td>    0.802</td> <td>    1.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log low warehouse</th> <td>    0.0314</td> <td>    0.047</td> <td>    0.673</td> <td> 0.501</td> <td>   -0.060</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LOW entry</th>         <td>    1.3580</td> <td>    0.098</td> <td>   13.845</td> <td> 0.000</td> <td>    1.166</td> <td>    1.550</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Northeast</th>         <td>   -0.2009</td> <td>    0.162</td> <td>   -1.242</td> <td> 0.214</td> <td>   -0.518</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Midwest</th>           <td>   -0.3065</td> <td>    0.128</td> <td>   -2.397</td> <td> 0.017</td> <td>   -0.557</td> <td>   -0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>South</th>             <td>   -0.2451</td> <td>    0.125</td> <td>   -1.961</td> <td> 0.050</td> <td>   -0.490</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               HD entry   No. Observations:                 2952\n",
       "Model:                          Logit   Df Residuals:                     2944\n",
       "Method:                           MLE   Df Model:                            7\n",
       "Date:                Thu, 01 Jul 2021   Pseudo R-squ.:                  0.1988\n",
       "Time:                        14:56:02   Log-Likelihood:                -1519.9\n",
       "converged:                       True   LL-Null:                       -1897.2\n",
       "Covariance Type:            nonrobust   LLR p-value:                1.246e-158\n",
       "=====================================================================================\n",
       "                        coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "const               -10.3008      1.489     -6.918      0.000     -13.219      -7.382\n",
       "log income           -0.0317      0.131     -0.242      0.808      -0.288       0.225\n",
       "log population        0.9161      0.058     15.694      0.000       0.802       1.031\n",
       "log low warehouse     0.0314      0.047      0.673      0.501      -0.060       0.123\n",
       "LOW entry             1.3580      0.098     13.845      0.000       1.166       1.550\n",
       "Northeast            -0.2009      0.162     -1.242      0.214      -0.518       0.116\n",
       "Midwest              -0.3065      0.128     -2.397      0.017      -0.557      -0.056\n",
       "South                -0.2451      0.125     -1.961      0.050      -0.490      -0.000\n",
       "=====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model fit for HD stores\n",
    "x = entry2_data[['log income','log population','log low warehouse','LOW entry','Northeast', 'Midwest', 'South']].copy()\n",
    "y = entry2_data['HD entry']\n",
    "model1 = sm.Logit(y,sm.add_constant(x)).fit()    # doesn't work when interaction term in model\n",
    "model1.summary()\n",
    "#print(model1.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
