{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22891254 0.99241473]\n",
      "[0.25786164 0.99371069]\n"
     ]
    }
   ],
   "source": [
    "def contraction(params, x, p):\n",
    "    # beta and x are kind of parameters. x is the empirical distribution of x?\n",
    "    k = int(x.shape[1]/2)\n",
    "    util1 = np.dot(x[:, 0:k], params[0:k]) + params[-2]*p[:,1]\n",
    "    util2 = np.dot(x[:, k:2*k], params[k:2*k]) + params[-1]*p[:,0]\n",
    "    contr_result = [np.exp(util1)/(1+np.exp(util1)),\n",
    "                    np.exp(util2)/(1+np.exp(util2))]\n",
    "    return np.array(contr_result).transpose()\n",
    "\n",
    "\n",
    "def contraction_map(betas, x, p):\n",
    "    \"\"\"final result is beliefs of firm1/firm2\"\"\"\n",
    "    for i in range(50):\n",
    "        p = contraction(betas, x, p)\n",
    "    return p\n",
    "\n",
    "#actually caclualte an equilibrium in this game\n",
    "N=1000\n",
    "ps = np.random.randint(2, size=(N,2))\n",
    "betas = np.array([1, 2, -2, -1])\n",
    "\n",
    "#set up xs\n",
    "xs = np.random.normal(scale=2, size=(N,2)) #assumes xs are independent? could use a copula?\n",
    "xs = pd.DataFrame(xs,columns = ['x11','x12'])\n",
    "xs = np.array(xs)\n",
    "\n",
    "\n",
    "result_ps = contraction_map(betas,xs,ps)\n",
    "us = np.random.logistic(size=(1000,2))\n",
    "\n",
    "k = int(xs.shape[1]/2)\n",
    "es = np.random.logistic(0, 1, (2,N) )\n",
    "y1 = 1*(np.dot(xs[:, 0:k], betas[0:k])  + betas[-2]*result_ps[:,1] + es[0,:] >= 0)\n",
    "y2 = 1*(np.dot(xs[:, k:2*k], betas[k:2*k]) + betas[-1]*result_ps[:,0] + es[1,:] >= 0)\n",
    "ys = np.array([y1,y2]).transpose()\n",
    "\n",
    "print(result_ps[(xs[:,1] > 2)].mean(axis=0))\n",
    "print(ys[ (xs[:,1] > 2) ].mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      y1   y2       x11       x12\n",
      "0    1.0  1.0  1.447096 -0.335568\n",
      "1    0.0  0.0 -2.028109  1.342185\n",
      "2    0.0  0.0 -2.047590  1.051197\n",
      "3    1.0  0.0  0.210241  5.307622\n",
      "4    1.0  0.0  0.127428 -0.638337\n",
      "5    0.0  0.0  1.271709  2.044584\n",
      "6    0.0  0.0  1.191651  0.940567\n",
      "7    1.0  0.0  2.382297 -0.404524\n",
      "8    0.0  1.0 -2.319361 -0.648141\n",
      "9    1.0  0.0 -0.747293  0.518130\n",
      "10   1.0  0.0  1.458985  2.000117\n",
      "11   1.0  0.0  1.597644  2.076300\n",
      "12   0.0  0.0 -2.741154  2.825788\n",
      "13   0.0  0.0  0.806281  0.679686\n",
      "14   1.0  0.0  0.004437  1.203134\n",
      "15   0.0  0.0 -2.409205 -0.514022\n",
      "16   1.0  0.0  0.605987  2.574417\n",
      "17   1.0  1.0  0.744964 -1.799538\n",
      "18   0.0  0.0  0.039920  2.356177\n",
      "19   1.0  1.0  1.768667 -0.490208\n",
      "20   0.0  0.0 -3.852982  1.192318\n",
      "21   0.0  0.0 -0.388696  3.767995\n",
      "22   0.0  0.0 -1.522841  1.962196\n",
      "23   1.0  1.0  2.562621 -0.610767\n",
      "24   0.0  0.0 -1.423437  1.080170\n",
      "25   0.0  0.0 -1.081572  0.362647\n",
      "26   1.0  1.0 -0.178557 -1.421174\n",
      "27   1.0  1.0 -0.281594 -2.891395\n",
      "28   1.0  1.0  2.125843 -1.584223\n",
      "29   1.0  0.0  2.980131  0.404703\n",
      "..   ...  ...       ...       ...\n",
      "970  1.0  0.0 -0.200704  2.623185\n",
      "971  0.0  0.0  0.224225  0.401376\n",
      "972  1.0  1.0  0.747978 -0.058897\n",
      "973  0.0  1.0 -4.060252 -1.169320\n",
      "974  0.0  0.0  0.042810 -0.292240\n",
      "975  1.0  1.0  0.123069 -1.888260\n",
      "976  1.0  1.0  1.312952 -2.128489\n",
      "977  1.0  1.0  3.050366 -3.210487\n",
      "978  1.0  0.0 -1.167318  0.985826\n",
      "979  0.0  1.0 -1.833976 -1.678291\n",
      "980  0.0  0.0 -1.072033  1.542504\n",
      "981  1.0  1.0  0.631664 -0.780145\n",
      "982  0.0  0.0  0.432523  1.315120\n",
      "983  1.0  1.0  2.550741 -2.399253\n",
      "984  0.0  0.0 -1.093820  3.037819\n",
      "985  0.0  0.0 -0.852042 -1.611595\n",
      "986  0.0  1.0 -3.620128  0.336399\n",
      "987  1.0  0.0  1.456723 -0.541536\n",
      "988  1.0  1.0  0.452146 -2.152835\n",
      "989  0.0  1.0 -0.446955 -1.766024\n",
      "990  0.0  1.0 -1.078256 -1.155642\n",
      "991  1.0  0.0  2.111536  0.045413\n",
      "992  0.0  1.0 -1.433896 -1.117611\n",
      "993  1.0  1.0  0.538516 -0.781434\n",
      "994  1.0  0.0  1.634806  2.805575\n",
      "995  1.0  1.0  2.199194 -2.864276\n",
      "996  0.0  1.0 -1.045191 -2.422083\n",
      "997  1.0  0.0  0.709414  2.280821\n",
      "998  0.0  0.0 -0.879960 -0.061990\n",
      "999  1.0  1.0  2.379890 -2.740623\n",
      "\n",
      "[1000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "result_df = np.concatenate( (ys,xs ) ,axis=1)\n",
    "result_df = pd.DataFrame(result_df, columns=['y1','y2','x11','x12'])\n",
    "print(result_df)\n",
    "result_df.to_csv('monte_carlo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.736559\n",
      "         Iterations: 239\n",
      "         Function evaluations: 475\n",
      "                            BayesNashLogit Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           ['y1', 'y2']   Log-Likelihood:                -736.56\n",
      "Model:                 BayesNashLogit   AIC:                             1477.\n",
      "Method:            Maximum Likelihood   BIC:                             1487.\n",
      "Date:                Fri, 30 Apr 2021                                         \n",
      "Time:                        13:14:51                                         \n",
      "No. Observations:                1000                                         \n",
      "Df Residuals:                     998                                         \n",
      "Df Model:                           1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "b11            1.0448      0.068     15.402      0.000       0.912       1.178\n",
      "d1            -1.9917      0.201     -9.911      0.000      -2.386      -1.598\n",
      "b12            1.7904      0.116     15.409      0.000       1.563       2.018\n",
      "d2            -0.6780      0.276     -2.453      0.014      -1.220      -0.136\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "class BayesNashLogit(GenericLikelihoodModel):\n",
    "    \n",
    "    def nloglikeobs(self, params):\n",
    "        n = self.exog.shape[0]\n",
    "        k = int(self.exog.shape[1]/2)\n",
    "        \n",
    "        p = self.endog.mean(axis=0)\n",
    "        p = contraction_map(params,self.exog,p)\n",
    "        \n",
    "        likelihood = contraction(params,self.exog,p).transpose()\n",
    "        ll = self.endog*np.log(likelihood) + (1-self.endog)*np.log(1-likelihood)\n",
    "        return -1*ll.sum(axis=1)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def fit(self, **kwds):\n",
    "        \"\"\"fit the likelihood function using the right start parameters\"\"\"\n",
    "        start_params = np.ones(self.exog.shape[1]+2)\n",
    "        return super(BayesNashLogit, self).fit(start_params=start_params,**kwds)\n",
    "\n",
    "        \n",
    "        \n",
    "N = result_df.shape[0]\n",
    "ys = result_df[['y1','y2']]\n",
    "xs = result_df[['x11' ,'x12']]\n",
    "print(xs.shape)\n",
    "\n",
    "model = BayesNashLogit(ys,xs)\n",
    "model.loglikeobs(np.ones(xs.shape[1]+2))\n",
    "model_fit = model.fit(xtol=1e-12,ftol=1e-12)\n",
    "print(model_fit.summary(xname=[\"b11\",\"d1\",\"b12\",\"d2\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempt at standard errors...\n",
    "H = np.linalg.inv(model.hessian(model_fit.params)/N)\n",
    "diag = np.diagonal(np.linalg.inv(model.hessian(model_fit.params)))\n",
    "print(np.sqrt(-1*diag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the variables\n",
    "entry_data = pd.read_csv(\"merged_entry.csv\")\n",
    "entry_data.loc[entry_data['HD'] > 0.0, 'HD_1'] = 1\n",
    "entry_data.loc[entry_data['LO'] > 0.0, 'LO_1'] = 1\n",
    "entry_data['income_2'] = np.log(1 + entry_data['income_per_capita'])\n",
    "entry_data['population_2'] = np.log(1 + entry_data['population'])\n",
    "entry_data['under44_1_2'] = np.log(1 + entry_data['under44_1'])\n",
    "entry_data['under44_2_2'] = np.log(1 + entry_data['under44_2'])\n",
    "entry_data['under44_3_2'] = np.log(1 + entry_data['under44_3'])\n",
    "entry_data['older65_1_2'] = np.log(1 + entry_data['older65_1'])\n",
    "entry_data['older65_2_2'] = np.log(1 + entry_data['older_65_2'])\n",
    "entry_data = entry_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himan\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:567: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warn(\"Maximum Likelihood optimization failed to converge. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>BayesNashLogit Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>['HD_1', 'LO_1']</td>  <th>  Log-Likelihood:    </th> <td> -2730.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>              <td>BayesNashLogit</td>   <th>  AIC:               </th> <td>   5465.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>           <td>Maximum Likelihood</td> <th>  BIC:               </th> <td>   5477.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 19 Apr 2021</td>  <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>10:09:57</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  2155</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  2153</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>     1</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income_2</th>     <td>   -0.2697</td> <td>    0.040</td> <td>   -6.752</td> <td> 0.000</td> <td>   -0.348</td> <td>   -0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>population_2</th> <td>    0.2743</td> <td>    0.038</td> <td>    7.155</td> <td> 0.000</td> <td>    0.199</td> <td>    0.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income_2</th>     <td>    2.1167</td> <td>    0.301</td> <td>    7.033</td> <td> 0.000</td> <td>    1.527</td> <td>    2.707</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>population_2</th> <td>   -0.2629</td> <td>    0.037</td> <td>   -7.144</td> <td> 0.000</td> <td>   -0.335</td> <td>   -0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>par0</th>         <td>    0.1446</td> <td>    0.034</td> <td>    4.286</td> <td> 0.000</td> <td>    0.078</td> <td>    0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>par1</th>         <td>    1.6739</td> <td>    0.220</td> <td>    7.614</td> <td> 0.000</td> <td>    1.243</td> <td>    2.105</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            BayesNashLogit Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       ['HD_1', 'LO_1']   Log-Likelihood:                -2730.7\n",
       "Model:                 BayesNashLogit   AIC:                             5465.\n",
       "Method:            Maximum Likelihood   BIC:                             5477.\n",
       "Date:                Mon, 19 Apr 2021                                         \n",
       "Time:                        10:09:57                                         \n",
       "No. Observations:                2155                                         \n",
       "Df Residuals:                    2153                                         \n",
       "Df Model:                           1                                         \n",
       "================================================================================\n",
       "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "income_2        -0.2697      0.040     -6.752      0.000      -0.348      -0.191\n",
       "population_2     0.2743      0.038      7.155      0.000       0.199       0.350\n",
       "income_2         2.1167      0.301      7.033      0.000       1.527       2.707\n",
       "population_2    -0.2629      0.037     -7.144      0.000      -0.335      -0.191\n",
       "par0             0.1446      0.034      4.286      0.000       0.078       0.211\n",
       "par1             1.6739      0.220      7.614      0.000       1.243       2.105\n",
       "================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "N = entry_data.shape[0]\n",
    "x = entry_data[['income_2','population_2','income_2','population_2']].copy()\n",
    "y = entry_data[['HD_1','LO_1']]\n",
    "\n",
    "model = BayesNashLogit(y,x).fit(xtol=1e-6,ftol=1e-6)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
