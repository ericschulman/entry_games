{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "\n",
    "\n",
    "#TODO: This file has problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22039895 0.99342023]\n",
      "[0.24203822 0.98089172]\n"
     ]
    }
   ],
   "source": [
    "def contraction(params, x, p):\n",
    "    # beta and x are kind of parameters. x is the empirical distribution of x?\n",
    "    k = int(x.shape[1]/2)\n",
    "    util1 = np.dot(x[:, 0:k], params[0:k]) + params[-2]*p[:,1]\n",
    "    util2 = np.dot(x[:, k:2*k], params[k:2*k]) + params[-1]*p[:,0]\n",
    "    contr_result = [np.exp(util1)/(1+np.exp(util1)),\n",
    "                    np.exp(util2)/(1+np.exp(util2))]\n",
    "    return np.array(contr_result).transpose()\n",
    "\n",
    "\n",
    "def contraction_map(betas, x, p):\n",
    "    \"\"\"final result is beliefs of firm1/firm2\"\"\"\n",
    "    for i in range(50):\n",
    "        p = contraction(betas, x, p)\n",
    "    return p\n",
    "\n",
    "#actually caclualte an equilibrium in this game\n",
    "N=1000\n",
    "ps = np.random.randint(2, size=(N,2))\n",
    "betas = np.array([1, 2, -2, -1])\n",
    "\n",
    "#set up xs\n",
    "xs = np.random.normal(scale=2, size=(N,2)) #assumes xs are independent? could use a copula?\n",
    "xs = pd.DataFrame(xs,columns = ['x11','x12'])\n",
    "xs = np.array(xs)\n",
    "\n",
    "\n",
    "result_ps = contraction_map(betas,xs,ps)\n",
    "us = np.random.logistic(size=(1000,2))\n",
    "\n",
    "k = int(xs.shape[1]/2)\n",
    "es = np.random.logistic(0, 1, (2,N) )\n",
    "y1 = 1*(np.dot(xs[:, 0:k], betas[0:k])  + betas[-2]*result_ps[:,1] + es[0,:] >= 0)\n",
    "y2 = 1*(np.dot(xs[:, k:2*k], betas[k:2*k]) + betas[-1]*result_ps[:,0] + es[1,:] >= 0)\n",
    "ys = np.array([y1,y2]).transpose()\n",
    "\n",
    "print(result_ps[(xs[:,1] > 2)].mean(axis=0))\n",
    "print(ys[ (xs[:,1] > 2) ].mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      y1   y2       x11       x12\n",
      "0    0.0  0.0 -1.602443 -0.906795\n",
      "1    1.0  1.0  1.949413 -0.370789\n",
      "2    1.0  0.0  1.308314 -0.680240\n",
      "3    0.0  0.0 -2.743767 -2.448277\n",
      "4    0.0  0.0  0.093243 -0.490898\n",
      "..   ...  ...       ...       ...\n",
      "995  0.0  0.0 -2.207663 -1.350822\n",
      "996  0.0  0.0 -2.520320 -1.620732\n",
      "997  0.0  1.0 -2.212792  0.949326\n",
      "998  0.0  0.0 -0.501389 -1.285246\n",
      "999  1.0  0.0  1.374238 -1.476167\n",
      "\n",
      "[1000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "result_df = np.concatenate( (ys,xs ) ,axis=1)\n",
    "result_df = pd.DataFrame(result_df, columns=['y1','y2','x11','x12'])\n",
    "print(result_df)\n",
    "result_df.to_csv('monte_carlo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.439798\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.279011\n",
      "         Iterations 8\n",
      "[ 0.9614755   1.97953106 -1.46233359 -0.43453159]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.698254\n",
      "         Iterations: 174\n",
      "         Function evaluations: 388\n",
      "                            BayesNashLogit Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           ['y1', 'y2']   Log-Likelihood:                -698.25\n",
      "Model:                 BayesNashLogit   AIC:                             1401.\n",
      "Method:            Maximum Likelihood   BIC:                             1410.\n",
      "Date:                Tue, 10 May 2022                                         \n",
      "Time:                        08:56:39                                         \n",
      "No. Observations:                1000                                         \n",
      "Df Residuals:                     998                                         \n",
      "Df Model:                           1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "b11            1.0058      0.068     14.872      0.000       0.873       1.138\n",
      "d1             1.9767      0.127     15.593      0.000       1.728       2.225\n",
      "b12           -1.8780      0.162    -11.609      0.000      -2.195      -1.561\n",
      "d2            -0.6973      0.224     -3.110      0.002      -1.137      -0.258\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "class BayesNashLogit(GenericLikelihoodModel):\n",
    "    \n",
    "    def nloglikeobs(self, params):\n",
    "        n = self.exog.shape[0]\n",
    "        k = int(self.exog.shape[1]/2)\n",
    "\n",
    "        p = self.endog\n",
    "        p = contraction_map(params, self.exog, p)\n",
    "\n",
    "        likelihood = contraction(params, self.exog, p)\n",
    "        ll = self.endog*np.log(likelihood) + \\\n",
    "            (1-self.endog)*np.log(1-likelihood)\n",
    "        return -1*ll.sum(axis=1)\n",
    "\n",
    "        \n",
    "    \n",
    "    def fit(self, **kwds):\n",
    "        \"\"\"fit the likelihood function using the right start parameters\"\"\"\n",
    "        k = int(self.exog.shape[1]/2)\n",
    "        x1 = np.concatenate( (self.exog[:, 0:k], self.endog[:,1].reshape(self.endog.shape[0],1) ) ,axis=1)\n",
    "        x2 = np.concatenate( (self.exog[:, k:2*k], self.endog[:,0].reshape(self.endog.shape[0],1) ),axis=1)\n",
    "        params1 =  sm.Logit(self.endog[:, 0], x1).fit().params\n",
    "        params2 = sm.Logit(self.endog[:, 1], x2).fit().params\n",
    "        start_params = np.concatenate((params1[0:-1],params2[0:-1],[params1[-1],params2[-1]] ))\n",
    "        print(start_params)\n",
    "        return super(BayesNashLogit, self).fit(start_params=start_params, **kwds)\n",
    "\n",
    "        \n",
    "        \n",
    "N = result_df.shape[0]\n",
    "ys = result_df[['y1','y2']]\n",
    "xs = result_df[['x11' ,'x12']]\n",
    "print(xs.shape)\n",
    "\n",
    "model = BayesNashLogit(ys,xs)\n",
    "model.loglikeobs(np.ones(xs.shape[1]+2))\n",
    "model_fit = model.fit(xtol=1e-12,ftol=1e-12)\n",
    "print(model_fit.summary(xname=[\"b11\",\"d1\",\"b12\",\"d2\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06763441 0.12676757 0.16177376 0.22419225]\n"
     ]
    }
   ],
   "source": [
    "#attempt at standard errors...\n",
    "H = np.linalg.inv(model.hessian(model_fit.params)/N)\n",
    "diag = np.diagonal(np.linalg.inv(model.hessian(model_fit.params)))\n",
    "print(np.sqrt(-1*diag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erichschulman/anaconda3/lib/python3.9/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Modify the variables\n",
    "entry_data = pd.read_csv(\"../data/merged_entry.csv\")\n",
    "entry_data.loc[entry_data['HD'] > 0.0, 'HD_1'] = 1\n",
    "entry_data.loc[entry_data['LO'] > 0.0, 'LO_1'] = 1\n",
    "entry_data['income_2'] = np.log(1 + entry_data['income_per_capita'])\n",
    "entry_data['population_2'] = np.log(1 + entry_data['population'])\n",
    "entry_data['under44_1_2'] = np.log(1 + entry_data['under44_1'])\n",
    "entry_data['under44_2_2'] = np.log(1 + entry_data['under44_2'])\n",
    "entry_data['under44_3_2'] = np.log(1 + entry_data['under44_3'])\n",
    "entry_data['older65_1_2'] = np.log(1 + entry_data['older65_1'])\n",
    "entry_data['older65_2_2'] = np.log(1 + entry_data['older_65_2'])\n",
    "entry_data = entry_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.416220\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.520699\n",
      "         Iterations 7\n",
      "[-0.14254449  0.50316223 -0.13063233  0.42585139 -3.37383234 -3.33023913]\n",
      "Warning: Maximum number of iterations has been exceeded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erichschulman/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>BayesNashLogit Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>['HD_1', 'LO_1']</td>  <th>  Log-Likelihood:    </th> <td> -2676.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>              <td>BayesNashLogit</td>   <th>  AIC:               </th> <td>   5357.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>           <td>Maximum Likelihood</td> <th>  BIC:               </th> <td>   5368.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Tue, 10 May 2022</td>  <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>08:56:52</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  2155</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  2153</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>     1</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income_2</th>     <td>   -0.1636</td> <td>    0.038</td> <td>   -4.280</td> <td> 0.000</td> <td>   -0.239</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>population_2</th> <td>    0.2182</td> <td>    0.042</td> <td>    5.207</td> <td> 0.000</td> <td>    0.136</td> <td>    0.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income_2</th>     <td>   -0.1831</td> <td>    0.034</td> <td>   -5.339</td> <td> 0.000</td> <td>   -0.250</td> <td>   -0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>population_2</th> <td>    0.2013</td> <td>    0.036</td> <td>    5.534</td> <td> 0.000</td> <td>    0.130</td> <td>    0.273</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>par0</th>         <td>    1.0537</td> <td>    0.282</td> <td>    3.732</td> <td> 0.000</td> <td>    0.500</td> <td>    1.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>par1</th>         <td>    0.1174</td> <td>    0.216</td> <td>    0.543</td> <td> 0.587</td> <td>   -0.306</td> <td>    0.541</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            BayesNashLogit Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       ['HD_1', 'LO_1']   Log-Likelihood:                -2676.3\n",
       "Model:                 BayesNashLogit   AIC:                             5357.\n",
       "Method:            Maximum Likelihood   BIC:                             5368.\n",
       "Date:                Tue, 10 May 2022                                         \n",
       "Time:                        08:56:52                                         \n",
       "No. Observations:                2155                                         \n",
       "Df Residuals:                    2153                                         \n",
       "Df Model:                           1                                         \n",
       "================================================================================\n",
       "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "income_2        -0.1636      0.038     -4.280      0.000      -0.239      -0.089\n",
       "population_2     0.2182      0.042      5.207      0.000       0.136       0.300\n",
       "income_2        -0.1831      0.034     -5.339      0.000      -0.250      -0.116\n",
       "population_2     0.2013      0.036      5.534      0.000       0.130       0.273\n",
       "par0             1.0537      0.282      3.732      0.000       0.500       1.607\n",
       "par1             0.1174      0.216      0.543      0.587      -0.306       0.541\n",
       "================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "N = entry_data.shape[0]\n",
    "x = entry_data[['income_2','population_2','income_2','population_2']].copy()\n",
    "y = entry_data[['HD_1','LO_1']]\n",
    "\n",
    "model = BayesNashLogit(y,x).fit(xtol=1e-6,ftol=1e-6)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
