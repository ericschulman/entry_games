{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"monte_carlo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "                              NashLogit Results                               \n",
      "==============================================================================\n",
      "Dep. Variable:           ['y1', 'y2']   Log-Likelihood:                -576.50\n",
      "Model:                      NashLogit   AIC:                             1159.\n",
      "Method:            Maximum Likelihood   BIC:                             1174.\n",
      "Date:                Fri, 05 Mar 2021                                         \n",
      "Time:                        14:20:31                                         \n",
      "No. Observations:                1000                                         \n",
      "Df Residuals:                     997                                         \n",
      "Df Model:                           2                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "b01            0.9972      0.188      5.312      0.000       0.629       1.365\n",
      "b11            4.1762      0.298     14.008      0.000       3.592       4.760\n",
      "d1            -2.9640      0.312     -9.497      0.000      -3.576      -2.352\n",
      "b02            1.9879      0.191     10.395      0.000       1.613       2.363\n",
      "b12            2.8256      0.186     15.157      0.000       2.460       3.191\n",
      "d2            -2.1609      0.249     -8.678      0.000      -2.649      -1.673\n",
      "rho          -15.2509    633.348     -0.024      0.981   -1256.591    1226.089\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erichschulman/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "class NashLogit(GenericLikelihoodModel):\n",
    "    \n",
    "    def nloglikeobs(self, params):\n",
    "        n = self.exog.shape[0]\n",
    "        k = int(self.exog.shape[1]/2)\n",
    "        p = np.zeros((2,2,n))\n",
    "\n",
    "        for a_j in [0,1]:\n",
    "            util1 = np.dot(self.exog[:,0:k], params[0:k])  + params[k]*a_j\n",
    "            util2 = np.dot(self.exog[:,k:], params[k+1:2*k+1]) + params[2*k+1]*a_j\n",
    "            p[0,a_j,:] = 1 /(1 + np.exp(util1))\n",
    "            p[1,a_j,:] = 1 /(1 + np.exp(util2))\n",
    "        \n",
    "        lamb = np.exp(params[-1])/(1+np.exp(params[-1]))\n",
    "        \n",
    "        #solve for probablity of nash\n",
    "        mult_eq = np.maximum( ( p[0,1,:]  - p[0,0,:] )*(  p[1,1,:] - p[1,0,:] ),0)\n",
    "        prob01 = ( p[0,1,:] )*( 1 - p[1,0,:] ) - (1-lamb)*mult_eq\n",
    "        prob10 = ( 1 - p[0,0,:] )*( p[1,1,:] ) - (lamb)*mult_eq\n",
    "        prob00 = p[0,0,:] * p[1,0,:]\n",
    "        prob11 = ( 1 - p[0,1,:] )*( 1 - p[1,1,:] )\n",
    "\n",
    "        #compute empirical likelihood\n",
    "        p00 = (1 - self.endog[:,0])*(1 - self.endog[:,1])\n",
    "        p11 = self.endog[:,0]*self.endog[:,1]\n",
    "        p10 = self.endog[:,0]* (1 - self.endog[:,1])\n",
    "        p01 = (1 - self.endog[:,0]) * self.endog[:,1]\n",
    "\n",
    "        ll = p00 * prob00 + p11 *prob11 + p01 * prob01 + p10 * prob10\n",
    "        \n",
    "       \n",
    "        return -np.log(ll).sum()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def fit(self, **kwds):\n",
    "        \"\"\"fit the likelihood function using the right start parameters\"\"\"\n",
    "        start_params = np.ones(self.exog.shape[1]+3)\n",
    "        start_params = np.array([1, 4, -3 ,2, 3, -2 ,-1])\n",
    "        return super(NashLogit, self).fit(start_params=start_params,**kwds)\n",
    "\n",
    "        \n",
    "        \n",
    "N = data.shape[0]\n",
    "y = data[['y1','y2']]\n",
    "x = data[['x1','x2']]\n",
    "\n",
    "x.insert(0,'x01',np.ones(N))\n",
    "x.insert(2,'x02',np.ones(N))\n",
    "\n",
    "model = NashLogit(y,x)\n",
    "model = model.fit()\n",
    "print(model.summary(xname=[\"b01\",\"b11\",\"d1\",\"b02\",\"b12\",\"d2\",\"rho\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
