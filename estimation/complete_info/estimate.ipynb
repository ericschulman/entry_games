{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"monte_carlo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.459321\n",
      "         Iterations: 287\n",
      "         Function evaluations: 451\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "                              NashLogit Results                               \n",
      "==============================================================================\n",
      "Dep. Variable:           ['y1', 'y2']   Log-Likelihood:                -459.32\n",
      "Model:                      NashLogit   AIC:                             924.6\n",
      "Method:            Maximum Likelihood   BIC:                             939.4\n",
      "Date:                Wed, 12 May 2021                                         \n",
      "Time:                        17:33:34                                         \n",
      "No. Observations:                1000                                         \n",
      "Df Residuals:                     997                                         \n",
      "Df Model:                           2                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "b01            0.6897      0.267      2.580      0.010       0.166       1.214\n",
      "b11            3.8496      0.296     12.993      0.000       3.269       4.430\n",
      "d1             3.1078      0.397      7.824      0.000       2.329       3.886\n",
      "b02            2.2120      0.234      9.433      0.000       1.752       2.672\n",
      "b12            2.8665      0.238     12.038      0.000       2.400       3.333\n",
      "d2             1.7798      0.342      5.206      0.000       1.110       2.450\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "class NashLogit(GenericLikelihoodModel):\n",
    "\n",
    "    def nloglikeobs(self, params):\n",
    "        n = self.exog.shape[0]\n",
    "        k = int(self.exog.shape[1]/2)\n",
    "        p = np.zeros((2, 2, n))\n",
    "\n",
    "        for a_j in [0, 1]:\n",
    "            util1 = np.dot(self.exog[:, 0:k], params[0:k]) + params[k]*a_j\n",
    "            util2 = np.dot(self.exog[:, k:],\n",
    "                           params[k+1:2*k+1]) + params[2*k+1]*a_j\n",
    "            p[0, a_j, :] = 1 / (1 + np.exp(util1))\n",
    "            p[1, a_j, :] = 1 / (1 + np.exp(util2))\n",
    "        \n",
    "        #choose lambda\n",
    "        lamb = .5\n",
    "        delta_pos = 1*(params[2*k+1] >= 0)\n",
    "        \n",
    "        # solve for probablity of nash\n",
    "        mult_eq = (p[0, 1, :] - p[0, 0, :])* (p[1, 1, :] - p[1, 0, :])\n",
    "        prob01 = (p[0, 1, :])*(1 - p[1, 0, :]) - (1-delta_pos)*(1-lamb)*mult_eq\n",
    "        prob10 = (1 - p[0, 0, :])*(p[1, 1, :]) -  (1-delta_pos)*(lamb)*mult_eq\n",
    "        prob00 = p[0, 0, :] * p[1, 0, :] - delta_pos*(1-lamb)*mult_eq\n",
    "        prob11 = (1 - p[0, 1, :])*(1 - p[1, 1, :]) - delta_pos*(lamb)*mult_eq\n",
    "\n",
    "        # compute empirical likelihood\n",
    "        p00 = (1 - self.endog[:, 0])*(1 - self.endog[:, 1])\n",
    "        p11 = self.endog[:, 0]*self.endog[:, 1]\n",
    "        p10 = self.endog[:, 0] * (1 - self.endog[:, 1])\n",
    "        p01 = (1 - self.endog[:, 0]) * self.endog[:, 1]\n",
    "\n",
    "        ll = p00 * prob00 + p11 * prob11 + p01 * prob01 + p10 * prob10\n",
    "        return -np.log(np.maximum(ll, 1e-12))\n",
    "        \n",
    "        \n",
    "    \n",
    "    def fit(self, **kwds):\n",
    "        \"\"\"fit the likelihood function using the right start parameters\"\"\"\n",
    "        start_params = np.ones(self.exog.shape[1]+2)\n",
    "        return super(NashLogit, self).fit(start_params=start_params,**kwds)\n",
    "\n",
    "        \n",
    "        \n",
    "N = data.shape[0]\n",
    "y = data[['y1','y2']]\n",
    "x = data[['x1','x2']]\n",
    "x.insert(0,'x01',np.ones(N))\n",
    "x.insert(2,'x02',np.ones(N))\n",
    "\n",
    "\n",
    "model = NashLogit(y,x)\n",
    "model = model.fit()\n",
    "print(model.summary(xname=[\"b01\",\"b11\",\"d1\",\"b02\",\"b12\",\"d2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himan\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:679: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Modify the variables\n",
    "entry_data = pd.read_csv(\"merged_entry.csv\")\n",
    "entry_data.loc[entry_data['HD'] > 0.0, 'HD_1'] = 1\n",
    "entry_data.loc[entry_data['LO'] > 0.0, 'LO_1'] = 1\n",
    "entry_data['income_2'] = np.log(1 + entry_data['income_per_capita'])\n",
    "entry_data['population_2'] = np.log(1 + entry_data['population'])\n",
    "entry_data['under44_1_2'] = np.log(1 + entry_data['under44_1'])\n",
    "entry_data['under44_2_2'] = np.log(1 + entry_data['under44_2'])\n",
    "entry_data['under44_3_2'] = np.log(1 + entry_data['under44_3'])\n",
    "entry_data['older65_1_2'] = np.log(1 + entry_data['older65_1'])\n",
    "entry_data['older65_2_2'] = np.log(1 + entry_data['older_65_2'])\n",
    "entry_data = entry_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himan\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:547: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warn('Inverting hessian failed, no bse or cov_params '\n",
      "C:\\Users\\himan\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:567: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warn(\"Maximum Likelihood optimization failed to converge. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>NashLogit Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>['HD_1', 'LO_1']</td>  <th>  Log-Likelihood:    </th> <td> -4625.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>NashLogit</td>     <th>  AIC:               </th> <td>   9256.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>           <td>Maximum Likelihood</td> <th>  BIC:               </th> <td>   9267.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 19 Apr 2021</td>  <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>10:23:05</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  2155</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  2153</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>     1</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income_2</th>     <td>   -1.0573</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>population_2</th> <td>    1.1026</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income_2</th>     <td>    3.9061</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>population_2</th> <td>    0.0097</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>par0</th>         <td>    0.0336</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>par1</th>         <td>    0.0274</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                              NashLogit Results                               \n",
       "==============================================================================\n",
       "Dep. Variable:       ['HD_1', 'LO_1']   Log-Likelihood:                -4625.8\n",
       "Model:                      NashLogit   AIC:                             9256.\n",
       "Method:            Maximum Likelihood   BIC:                             9267.\n",
       "Date:                Mon, 19 Apr 2021                                         \n",
       "Time:                        10:23:05                                         \n",
       "No. Observations:                2155                                         \n",
       "Df Residuals:                    2153                                         \n",
       "Df Model:                           1                                         \n",
       "================================================================================\n",
       "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "income_2        -1.0573        nan        nan        nan         nan         nan\n",
       "population_2     1.1026        nan        nan        nan         nan         nan\n",
       "income_2         3.9061        nan        nan        nan         nan         nan\n",
       "population_2     0.0097        nan        nan        nan         nan         nan\n",
       "par0             0.0336        nan        nan        nan         nan         nan\n",
       "par1             0.0274        nan        nan        nan         nan         nan\n",
       "================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "N = entry_data.shape[0]\n",
    "x = entry_data[['income_2','population_2','income_2','population_2']].copy()\n",
    "y = entry_data[['HD_1','LO_1']]\n",
    "\n",
    "model = NashLogit(y,x).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
